{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:00:35.887208100Z",
     "start_time": "2023-08-28T05:00:35.593932900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Notebook imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import cv2\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:00:35.889217400Z",
     "start_time": "2023-08-28T05:00:35.616481900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "(training_images, training_labels), (testing_images, testing_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize image data\n",
    "training_images = training_images / 255.0\n",
    "testing_images = testing_images / 255.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:00:36.137222500Z",
     "start_time": "2023-08-28T05:00:35.632150100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data:\n",
      "Training images shape:  (60000,)\n",
      "Training labels shape:  (60000,)\n",
      "Testing images shape:  (10000, 28, 28)\n",
      "Testing labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data:')\n",
    "print('Training images shape: ', training_labels.shape)\n",
    "print('Training labels shape: ', training_labels.shape)\n",
    "print('Testing images shape: ', testing_images.shape)\n",
    "print('Testing labels shape: ', testing_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:00:36.145218800Z",
     "start_time": "2023-08-28T05:00:36.115793Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the model without CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model_without_cnn = keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:00:36.214291200Z",
     "start_time": "2023-08-28T05:00:36.138223200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compiling the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model_without_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:00:36.323216800Z",
     "start_time": "2023-08-28T05:00:36.168775400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fitting the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5011 - accuracy: 0.8235\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3782 - accuracy: 0.8634\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3378 - accuracy: 0.8777\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3116 - accuracy: 0.8866\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2937 - accuracy: 0.8903\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x21c0b7230a0>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Fitting the model')\n",
    "model_without_cnn.fit(training_images, training_labels, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:01:07.042864300Z",
     "start_time": "2023-08-28T05:00:36.190358600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluating the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8758\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.3442371189594269, 0.8758000135421753]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating the model')\n",
    "model_without_cnn.evaluate(testing_images, testing_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:01:08.497836100Z",
     "start_time": "2023-08-28T05:01:07.043863800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Make predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 345ms/step\n",
      "Prediction: 9 \t Actual: 9\n",
      "Prediction: 2 \t Actual: 2\n",
      "Prediction: 1 \t Actual: 1\n",
      "Prediction: 1 \t Actual: 1\n",
      "Prediction: 6 \t Actual: 6\n",
      "Prediction: 1 \t Actual: 1\n",
      "Prediction: 4 \t Actual: 4\n",
      "Prediction: 6 \t Actual: 6\n",
      "Prediction: 5 \t Actual: 5\n",
      "Prediction: 7 \t Actual: 7\n"
     ]
    }
   ],
   "source": [
    "predictions = model_without_cnn.predict(testing_images[:10])\n",
    "index = 0\n",
    "\n",
    "for prediction in predictions:\n",
    "\n",
    "    print(f'Prediction: {np.argmax(prediction)} \\t Actual: {testing_labels[index]}')\n",
    "    index = index + 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:01:08.751092800Z",
     "start_time": "2023-08-28T05:01:08.491249500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Going to see if it can detect other images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "classes = pd.Series({'tshirt or top': 0, 'trouser':1, 'pullover':2, 'dress':3, 'coat':4, 'sandal':5, 'shirt':6, 'sneaker':7, 'bag':8, 'ankle boot':9})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:01:08.823093200Z",
     "start_time": "2023-08-28T05:01:08.757089100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "Predicted class: 8\n",
      "Actual class: 8\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path of the image\n",
    "image_path = 'Bag.webp'\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Resize and preprocess the grayscale image\n",
    "input_size = (28, 28)  # Example input size from MNIST Fashion dataset\n",
    "resized_image = cv2.resize(gray_image, input_size)\n",
    "normalized_image = resized_image / 255.0  # Normalize pixel values\n",
    "\n",
    "# Convert to tensor and add batch dimension\n",
    "input_tensor = tf.convert_to_tensor(normalized_image[np.newaxis, ..., np.newaxis])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model_without_cnn.predict(input_tensor)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Prediction\n",
    "print('Predicted class:', predicted_class)\n",
    "print('Actual class:', classes.loc['bag'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:01:09.098796300Z",
     "start_time": "2023-08-28T05:01:08.791090700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the model with a CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Building the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 11, 11, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               102528    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,922\n",
      "Trainable params: 122,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Improving the model\n",
    "improved_model = tf.keras.Sequential([\n",
    "\n",
    "    # Convolution (applying a filter)\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Pooling (max value of every pixel)\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Original layers in the other neural network\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "improved_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:01:09.399114100Z",
     "start_time": "2023-08-28T05:01:09.105792500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compiling the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "improved_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:01:09.400104800Z",
     "start_time": "2023-08-28T05:01:09.344988400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fitting the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.4596 - accuracy: 0.8330\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.3086 - accuracy: 0.8869\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.2624 - accuracy: 0.9028\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.2314 - accuracy: 0.9152\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2086 - accuracy: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x21c0b6b05e0>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_model.fit(training_images, training_labels, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:03:35.064472900Z",
     "start_time": "2023-08-28T05:01:09.377463400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
      " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
      " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
     ]
    }
   ],
   "source": [
    "print(testing_labels[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:03:35.098486600Z",
     "start_time": "2023-08-28T05:03:34.899418500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experimenting with the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Editing the number of filters in the convolution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 13, 13, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               51328     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,098\n",
      "Trainable params: 55,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 24s 11ms/step - loss: 0.5017 - accuracy: 0.8177\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.3467 - accuracy: 0.8748\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3059 - accuracy: 0.8875\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2805 - accuracy: 0.8972\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2588 - accuracy: 0.9040\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x21c10407d00>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Editing convolutions\n",
    "convolutions_edited_model = tf.keras.Sequential([\n",
    "\n",
    "    # Convolution (applying a filter)\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Pooling (max value of every pixel)\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Original layers in the other neural network\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "convolutions_edited_model.summary()\n",
    "convolutions_edited_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "convolutions_edited_model.fit(training_images, training_labels, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:05:35.652843200Z",
     "start_time": "2023-08-28T05:03:35.122624600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.2983 - accuracy: 0.8886\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.29826605319976807, 0.8885999917984009]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolutions_edited_model.evaluate(testing_images, testing_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:05:37.614344200Z",
     "start_time": "2023-08-28T05:05:35.606074900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Accuracy goes down when the number of filters decreases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing a convolution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               692352    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 26s 13ms/step - loss: 0.4047 - accuracy: 0.8569\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.2745 - accuracy: 0.9004\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2319 - accuracy: 0.9137\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.1964 - accuracy: 0.9279\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1677 - accuracy: 0.9378\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 0.2557 - accuracy: 0.9111\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.2557075619697571, 0.9110999703407288]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Editing convolutions\n",
    "convolution_removed_model = tf.keras.Sequential([\n",
    "\n",
    "    # Convolution (applying a filter)\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Pooling (max value of every pixel)\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Original layers in the other neural network\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "convolution_removed_model.summary()\n",
    "convolution_removed_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "convolution_removed_model.fit(training_images, training_labels, epochs=5)\n",
    "convolution_removed_model.evaluate(testing_images, testing_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:07:55.177359Z",
     "start_time": "2023-08-28T05:05:37.567449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T05:07:55.179362700Z",
     "start_time": "2023-08-28T05:07:55.173338600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
